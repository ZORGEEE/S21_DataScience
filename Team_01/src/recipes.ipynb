{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4267090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import  os,joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor, RandomForestClassifier, VotingClassifier,StackingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression,Lasso\n",
    "from sklearn.svm import SVR,SVC \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import  make_scorer, mean_squared_error, accuracy_score,precision_score,get_scorer,classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151ff93",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Use the dataset from Epicurious collected by HugoDarwood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "03d563fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20052, 680)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/epi_r.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40a51f",
   "metadata": {},
   "source": [
    "\n",
    "### Filter the columns:\n",
    "the less non-ingredient columns in your dataset the better. You will predict the rating or rating category using only the ingredients and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "26c55e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = [\n",
    "    \"calories\", \"protein\", \"fat\", \"sodium\", \"#cakeweek\", \"#wasteless\",\n",
    "    \"22-minute meals\", \"3-ingredient recipes\", \"30 days of groceries\", \"advance prep required\", \"breakfast\", \"brunch\", \"dinner\",\n",
    "    \"lunch\", \"dessert\", \"appetizer\", \"snack\", \"snack week\", \"side\", \"quick & easy\", \"quick and healthy\",\n",
    "    \"advance prep required\", \"kid-friendly\", \"vegan\", \"vegetarian\", \"pescatarian\", \"low cal\", \"low fat\",\n",
    "    \"low sugar\", \"low/no sugar\", \"low carb\", \"low cholesterol\", \"low sodium\", \"fat free\", \"pot pie\",\n",
    "    \"sugar conscious\", \"healthy\", \"high fiber\", \"dairy free\", \"peanut free\", \"tree nut free\", \"soy free\",\n",
    "    \"kosher\", \"kosher for passover\", \"wheat/gluten-free\", \"no sugar added\", \"non-alcoholic\", \"alcoholic\", \"organic\",\n",
    "    \"tested & improved\", \"no-cook\", \"freeze/chill\", \"freezer food\", \"raw\", \"grill\", \"grill/barbecue\",\n",
    "    \"broil\", \"roast\", \"bake\", \"pan-fry\", \"deep-fry\", \"fry\", \"simmer\",\"fruit\",\"braise\",\n",
    "    \"steam\", \"stir-fry\", \"slow cooker\", \"pressure cooker\", \"smoker\", \"microwave\", \"food processor\",\n",
    "    \"blender\", \"potato salad\", \"double boiler\", \"ice cream machine\", \"juicer\", \"mandoline\", \"mortar and pestle\",\n",
    "    \"candy thermometer\", \"cookbook critic\", \"paleo\", \"cook like a diner\", \"house cocktail\", \"epi loves the microwave\", \"epi + ushg\",\n",
    "    \"sandwich theory\", \"friendsgiving\", \"family reunion\", \"anniversary\", \"birthday\", \"wedding\", \"engagement party\",\n",
    "    \"party\", \"picnic\", \"buffet\", \"potluck\", \"tailgating\", \"cocktail party\", \"super bowl\",\n",
    "    \"thanksgiving\", \"christmas\", \"christmas eve\", \"new year's eve\", \"new year's day\", \"meatball\", \"meatloaf\",\n",
    "    \"shower\", \"ramekin\", \"valentine's day\", \"st. patrick's day\", \"halloween\", \"hanukkah\", \"rosh hashanah/yom kippur\",\n",
    "    \"purim\", \"sukkot\", \"passover\", \"shavuot\", \"diwali\", \"kwanzaa\", \"ramadan\",\n",
    "    \"easter\", \"fourth of july\", \"bastille day\", \"mardi gras\", \"lunar new year\", \"oscars\", \"father's day\",\n",
    "    \"winter\", \"flaming hot summer\", \"back to school\", \"backyard bbq\", \"entertaining\", \"casserole/gratin\", \"pasta maker\",\n",
    "    \"pressure cooker\", \"sandwich\",\"sourdough\", \"washington, d.c.\", \"lasagna\", \"hot drink\",\n",
    "    \"house & garden\", \"quiche\", \"frittata\", \"fritter\", \"soufflé/meringue\", \"salad\",\n",
    "    \"salad dressing\", \"pizza\", \"cupcake\", \"cake\", \"cookie\", \"cookies\", \"brownie\",\n",
    "    \"muffin\", \"biscuit\", \"waffle\", \"pancake\", \"taco\", \"burrito\", \"omelet\",\"stew\",\"soup/stew\",\n",
    "    \"smoothie\", \"ice cream\", \"sorbet\", \"crêpe\", \"cobbler/crumble\", \"custard\",\n",
    "    \"candy\", \"marshmallow\", \"edible gift\", \"hors d'oeuvre\", \"condiment\", \"condiment/spread\", \"salsa\",\n",
    "    \"sauce\", \"rub\", \"marinade\", \"marinate\", \"pickles\", \"macaroni and cheese\", \"parade\",\n",
    "    \"suzanne goin\", \"dorie greenspan\", \"dip\", \"drink\", \"drinks\", \"aperitif\", \"digestif\",\n",
    "    \"cocktail\", \"spirit\", \"connecticut\", \"dallas\", \"denver\", \"stuffing/dressing\", \"spring\",\n",
    "    \"summer\", \"fall\", \"graduation\", \"pasadena\", \"boston\", \"beverly hills\", \"nancy silverton\",\n",
    "    \"oktoberfest\", \"poker/game night\", \"pie\", \"providence\", \"france\", \"italy\", \"spain\",\n",
    "    \"germany\", \"switzerland\", \"australia\", \"england\", \"santa monica\", \"kansas city\", \"kentucky derby\",\n",
    "    \"kidney friendly\", \"kitchen olympics\", \"idaho\", \"hummus\", \"minneapolis\", \"mixer\", \"no meat, no problem\",\n",
    "    \"persian new year\", \"sauté\", \"self\", \"ireland\", \"israel\", \"japan\", \"egypt\",\n",
    "    \"canada\", \"haiti\", \"jamaica\", \"mexico\", \"peru\", \"philippines\", \"bulgaria\",\n",
    "    \"cuba\", \"dominican republic\", \"georgia\", \"guam\", \"arizona\", \"alabama\", \"alaska\",\n",
    "    \"california\", \"colorado\", \"mother's day\", \"one-pot meal\", \"punch\", \"skewer\", \"florida\",\n",
    "    \"hawaii\", \"illinois\", \"indiana\", \"iowa\", \"kansas\", \"kentucky\", \"louisiana\",\n",
    "    \"maine\", \"maryland\", \"massachusetts\", \"labor day\", \"michigan\", \"minnesota\", \"mississippi\",\n",
    "    \"missouri\", \"nebraska\", \"new hampshire\", \"new jersey\", \"new mexico\", \"new orleans\", \"cambridge\",\n",
    "    \"new york\", \"bon appétit\", \"harpercollins\", \"gourmet\", \"frankenrecipe\", \"frozen dessert\", \"game\",\n",
    "    \"bon app��tit\", \"north carolina\", \"ohio\", \"weelicious\", \"chill\", \"oklahoma\", \"oregon\",\n",
    "    \"pennsylvania\", \"rhode island\", \"south carolina\", \"tennessee\", \"texas\", \"utah\", \"vermont\",\n",
    "    \"virginia\", \"washington\", \"west virginia\", \"wisconsin\", \"las vegas\", \"los angeles\", \"brooklyn\",\n",
    "    \"atlanta\", \"columbus\", \"anthony bourdain\", \"houston\", \"emeril lagasse\", \"miami\", \"long beach\",\n",
    "    \"san francisco\", \"seattle\", \"portland\", \"pittsburgh\", \"louisville\", \"windsor\", \"westwood\",\n",
    "    \"lancaster\", \"healdsburg\", \"yonkers\", \"paris\", \"aspen\", \"costa mesa\", \"pacific palisades\",\n",
    "    \"st. louis\", \"cookbooks\", \"leftovers\"\n",
    "]\n",
    "df = df.drop(black_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4ca6edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['title', 'rating'], axis=1)\n",
    "y = df['rating']\n",
    "X_train, X_test, y_train,  y_test = train_test_split(x,y,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c612926",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fce879",
   "metadata": {},
   "source": [
    "Try different algorithms and their hyperparameters for rating\n",
    "prediction.\n",
    "\n",
    "Choose the best on cross-validation and find the score (RMSE) on the test\n",
    "subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c713a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    \"linearregression__fit_intercept\": [True, False]\n",
    "}\n",
    "param_grid_ridge = {\n",
    "    \"ridge__alpha\": [0.01, 0.1, 1, 10],\n",
    "    \"ridge__fit_intercept\": [True, False],\n",
    "    \"ridge__random_state\": [21]\n",
    "}\n",
    "param_grid_lasso = {\n",
    "    \"lasso__alpha\": [0.01, 0.1, 1, 10],\n",
    "    \"lasso__fit_intercept\": [True, False],\n",
    "    \"lasso__random_state\": [21]\n",
    "}\n",
    "param_grid_tree = {\n",
    "    \"max_depth\": [1, 5, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"random_state\": [21]\n",
    "}\n",
    "param_grid_svr = {\n",
    "    \"svr__kernel\": ['linear', 'rbf'],\n",
    "    \"svr__C\": [0.1, 1, 10],\n",
    "    \"svr__gamma\": ['scale', 'auto']\n",
    "}\n",
    "\n",
    "regressors_and_params = [\n",
    "    (\"LinearRegression\", make_pipeline(StandardScaler(), LinearRegression()), param_grid_lr),\n",
    "    (\"Ridge\", make_pipeline(StandardScaler(), Ridge()), param_grid_ridge),\n",
    "    (\"Lasso\", make_pipeline(StandardScaler(), Lasso()), param_grid_lasso),\n",
    "    (\"DecisionTree\", DecisionTreeRegressor(), param_grid_tree),\n",
    "    (\"SVR\", make_pipeline(StandardScaler(), SVR()), param_grid_svr)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a3a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_regressors(models_and_params, X_train, y_train, X_test, y_test, cv=5,scoring='neg_root_mean_squared_error'):\n",
    "    results = []\n",
    "\n",
    "    for name, model, param_grid in models_and_params:\n",
    "        grid = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        pred = best_model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test,pred))\n",
    "        results.append((name, grid.best_params_, rmse))\n",
    "        print(f\"{name}: best_params={grid.best_params_}, RMSE={rmse:.4f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d9a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: best_params={'linearregression__fit_intercept': True}, RMSE=1.2875\n",
      "Ridge: best_params={'ridge__alpha': 10, 'ridge__fit_intercept': True, 'ridge__random_state': 21}, RMSE=1.2875\n",
      "Lasso: best_params={'lasso__alpha': 0.01, 'lasso__fit_intercept': True, 'lasso__random_state': 21}, RMSE=1.2792\n",
      "DecisionTree: best_params={'max_depth': 5, 'min_samples_split': 10, 'random_state': 21}, RMSE=1.2983\n",
      "SVR: best_params={'svr__C': 1, 'svr__gamma': 'scale', 'svr__kernel': 'rbf'}, RMSE=1.3261\n"
     ]
    }
   ],
   "source": [
    "result = compare_regressors(regressors_and_params,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6f362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regressor class Lasso, hyperparametrs: {'lasso__alpha': 0.01, 'lasso__fit_intercept': True, 'lasso__random_state': 21}, RMSE = 1.279218937727105\n"
     ]
    }
   ],
   "source": [
    "result.sort(key=lambda x:x[2])\n",
    "print(f'Best regressor class {result[0][0]}, hyperparametrs: {result[0][1]}, RMSE = {result[0][2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1e99f",
   "metadata": {},
   "source": [
    "Try different `ensembles` and their `hyperparameters`. Choose the\n",
    "best on cross-validation and find the score on the test subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52f4d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid_rf = {'n_estimators':[50,100,200],\n",
    "                'max_depth':[5,10,20,30]}\n",
    "\n",
    "param_grid_gb = {\"n_estimators\": [50, 200],\n",
    "                \"learning_rate\": [0.03, 0.05],\n",
    "                \"max_depth\": [3, 5, 10],\n",
    "                \"min_samples_split\": [2, 10],\n",
    "                \"min_samples_leaf\": [1, 5],\n",
    "                \"subsample\": [0.4, 1.0],\n",
    "                \"max_features\": [\"auto\", \"sqrt\", \"log2\"]}\n",
    "base_learners_SR = [\n",
    "    ('ridge', make_pipeline(StandardScaler(), Ridge(alpha=10))),\n",
    "    ('lasso', make_pipeline(StandardScaler(), Lasso(alpha=0.01))),\n",
    "    ('tree', DecisionTreeRegressor(max_depth=5, min_samples_split=10))\n",
    "]\n",
    "\n",
    "param_grid_SR = {\n",
    "    \"final_estimator\": [\n",
    "        make_pipeline(StandardScaler(), Ridge()),\n",
    "        make_pipeline(StandardScaler(), Lasso()),\n",
    "        DecisionTreeRegressor(max_depth=3)\n",
    "    ],\n",
    "    \"passthrough\": [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c2dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_and_params = [('Random Forest', RandomForestRegressor(), param_grid_rf),\n",
    "                        ('Gradient Boosting', GradientBoostingRegressor(), param_grid_gb), \n",
    "                        ('Stacking Regressor',StackingRegressor(estimators=base_learners_SR), param_grid_SR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87eff761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: best_params={'max_depth': 30, 'n_estimators': 200}, RMSE=1.2870\n",
      "Gradient Boosting: best_params={'learning_rate': 0.05, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 1.0}, RMSE=1.2676\n",
      "Stacking Regressor: best_params={'final_estimator': Pipeline(steps=[('standardscaler', StandardScaler()), ('ridge', Ridge())]), 'passthrough': False}, RMSE=1.2785\n"
     ]
    }
   ],
   "source": [
    "ensembles_result = compare_regressors(ensembles_and_params,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737a96c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regressor class Gradient Boosting, hyperparametrs: {'learning_rate': 0.05, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 1.0}, RMSE = 1.2675945313781003\n"
     ]
    }
   ],
   "source": [
    "ensembles_result.sort(key=lambda x:x[2])\n",
    "print(f'Best regressor class {ensembles_result[0][0]}, hyperparametrs: {ensembles_result[0][1]}, RMSE = {ensembles_result[0][2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47523832",
   "metadata": {},
   "source": [
    "### Calculate the RMSE for a `naive regressor` that predicts the `average rating`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624f2ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний рейтинг = 3.7156310259990692\n"
     ]
    }
   ],
   "source": [
    "average_rating = [y_train.mean()] * len(y_test)\n",
    "print(f\"Средний рейтинг = {y_train.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8809eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive regressor RMSE  = 1.3281516046618942\n"
     ]
    }
   ],
   "source": [
    "naive_regressor_rmse = np.sqrt(mean_squared_error(y_test, average_rating))\n",
    "print(f\"Naive regressor RMSE  = {naive_regressor_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8967039",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793982e3",
   "metadata": {},
   "source": [
    "### Binarize the target column by rounding the ratings to the closest integer.\n",
    "This will be your classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b897bcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "4    9861\n",
       "5    2065\n",
       "0    1386\n",
       "3    1129\n",
       "2     471\n",
       "1     127\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_rounded,y_test_rounded = round(y_train,0).astype(int), round(y_test,0).astype(int),\n",
    "y_train_rounded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4205f",
   "metadata": {},
   "source": [
    "### Try different algorithms and their hyperparameters for class prediction.\n",
    "\n",
    "### Choose the best on cross-validation and find the score (accuracy) on the test subsample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "472b5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classificators(models_and_params, X_train, y_train, X_test, y_test, cv=5, scoring='accuracy'):\n",
    "    results = []\n",
    "    for name, model, param_grid in models_and_params:\n",
    "        grid = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        pred = best_model.predict(X_test)\n",
    "        if isinstance(scoring, str):\n",
    "            scorer = get_scorer(scoring)\n",
    "            metric = scorer(best_model, X_test, y_test)\n",
    "            metric_name = scoring\n",
    "        else:\n",
    "            metric = scoring._score_func(y_test, pred, **scoring._kwargs)\n",
    "            metric_name = scoring._score_func.__name__\n",
    "        results.append((name, grid.best_params_, metric))\n",
    "        print(f\"{name}: best_params={grid.best_params_}, {metric_name}={metric:.4f}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_SVC = {'kernel':['linear','rbf'],\n",
    "               'C':[0.1, 1], \n",
    "               'gamma':['scale','auto'], \n",
    "               'class_weight' : ['balanced', None],\n",
    "                'random_state':[21],\n",
    "                'probability':[True]}\n",
    "base_learners_SC = [\n",
    "    ('lr', make_pipeline(StandardScaler(),LogisticRegression(max_iter=1000))),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=5)),\n",
    "    ('svc', make_pipeline(StandardScaler(),SVC(probability=True, kernel='rbf')))\n",
    "]\n",
    "\n",
    "param_grid_SC = {\n",
    "    \"final_estimator\": [\n",
    "        make_pipeline(StandardScaler(),LogisticRegression(max_iter=1000)),\n",
    "        DecisionTreeClassifier(max_depth=3),\n",
    "        RandomForestClassifier(n_estimators=20)\n",
    "    ],\n",
    "    \"passthrough\": [True, False]\n",
    "}\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [False, True],\n",
    "    'estimator': [\n",
    "        DecisionTreeClassifier(max_depth=3),\n",
    "        DecisionTreeClassifier(max_depth=5)\n",
    "    ]\n",
    "}\n",
    "param_grid_logreg = {\n",
    "    'C': [0.1, 1, 10],               \n",
    "    'penalty': ['l2', 'l1', 'elasticnet', 'none'], \n",
    "    'solver': ['lbfgs', 'liblinear', 'saga', 'newton-cg'],\n",
    "    'max_iter': [100, 200]                   \n",
    "}\n",
    "base_learners_VC = [\n",
    "    ('lr', make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=5)),\n",
    "    ('svc', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "param_grid_voting = {\n",
    "    'voting': ['hard', 'soft'],\n",
    "    'weights': [\n",
    "        [1, 1, 1],  \n",
    "        [2, 1, 1],    \n",
    "        [1, 2, 1],    \n",
    "        [1, 1, 2]     \n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220bfe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificators_and_params = [('SVC',SVC(),param_grid_SVC),\n",
    "                             ('Stacking Classifier',StackingClassifier(base_learners_SC),param_grid_SC),\n",
    "                             ('Bagging Classifier',BaggingClassifier(),param_grid_bagging),\n",
    "                             ('Logistic Regression',LogisticRegression(),param_grid_logreg),\n",
    "                             ('VotingClassifier',VotingClassifier(base_learners_VC), param_grid_voting)\n",
    "                             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b36c4365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: best_params={'C': 1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'random_state': 21}, accuracy=0.6738\n",
      "Stacking Classifier: best_params={'final_estimator': DecisionTreeClassifier(max_depth=3), 'passthrough': False}, accuracy=0.6631\n",
      "Bagging Classifier: best_params={'bootstrap': False, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=5), 'max_features': 0.7, 'max_samples': 0.7, 'n_estimators': 10}, accuracy=0.6703\n",
      "Logistic Regression: best_params={'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}, accuracy=0.6703\n",
      "VotingClassifier: best_params={'voting': 'hard', 'weights': [1, 1, 1]}, accuracy=0.6699\n"
     ]
    }
   ],
   "source": [
    "classificator_result = compare_classificators(classificators_and_params,X_train.iloc[:5000],y_train_rounded.iloc[:5000],X_test,y_test_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d001fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classificator class SVC, hyperparametrs: {'C': 1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'random_state': 21}, Accuracy = 0.6738479952124476\n"
     ]
    }
   ],
   "source": [
    "classificator_result.sort(key=lambda x:-x[2])\n",
    "print(f'Best classificator class {classificator_result[0][0]}, hyperparametrs: {classificator_result[0][1]}, Accuracy = {classificator_result[0][2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f80fc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive model = 0.6636744464392579\n"
     ]
    }
   ],
   "source": [
    "most_common = [y_train_rounded.mode()] * len(y_test)\n",
    "naive_accuracy = accuracy_score(y_test_rounded,most_common)\n",
    "print(f'Accuracy of Naive model = {naive_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9501f69",
   "metadata": {},
   "source": [
    "### Binarize the target column again by converting the integers to classes ‘bad’ (0, 1), ‘so-so’ (2, 3), ‘great’ (4, 5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "30d4362d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "great    3981\n",
       "so-so     545\n",
       "bad       487\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [-np.inf,2,4,np.inf]\n",
    "labels = ['bad','so-so','great']\n",
    "y_train_labeled = pd.cut(y_train_rounded,bins=bins,labels=labels,right=False)\n",
    "y_test_labeled = pd.cut(y_test_rounded,bins=bins,labels=labels,right=False)\n",
    "y_test_labeled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "611d613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: best_params={'C': 1, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True, 'random_state': 21}, accuracy=0.7989\n",
      "Stacking Classifier: best_params={'final_estimator': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression(max_iter=1000))]), 'passthrough': False}, accuracy=0.7977\n",
      "Bagging Classifier: best_params={'bootstrap': False, 'bootstrap_features': True, 'estimator': DecisionTreeClassifier(max_depth=5), 'max_features': 1.0, 'max_samples': 0.7, 'n_estimators': 10}, accuracy=0.7983\n",
      "Logistic Regression: best_params={'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}, accuracy=0.7969\n",
      "VotingClassifier: best_params={'voting': 'hard', 'weights': [1, 1, 2]}, accuracy=0.7993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classificator_result_labels = compare_classificators(classificators_and_params,X_train.iloc[:5000],y_train_labeled.iloc[:5000],X_test,y_test_labeled,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8f6f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classificator class VotingClassifier, hyperparametrs: {'voting': 'hard', 'weights': [1, 1, 2]}, Accuracy = 0.7993217634151207\n"
     ]
    }
   ],
   "source": [
    "classificator_result_labels.sort(key=lambda x:-x[2])\n",
    "print(f'Best classificator class {classificator_result_labels[0][0]}, hyperparametrs: {classificator_result_labels[0][1]}, Accuracy = {classificator_result_labels[0][2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bbcdca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive model = 0.7941352483542788\n"
     ]
    }
   ],
   "source": [
    "most_common_label = [y_train_labeled.mode()] * len(y_test_labeled)\n",
    "naive_accuracy_labels = accuracy_score(y_test_labeled,most_common_label)\n",
    "print(f'Accuracy of Naive model = {naive_accuracy_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6a099",
   "metadata": {},
   "source": [
    "## What is worse: \n",
    "### to predict a bad rating which is good in real life, or to predict a good rating which is bad in real life? \n",
    "### Replace accuracy with the appropriate metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1716884",
   "metadata": {},
   "source": [
    "## Answer :\n",
    "### Хуже предсказать хороший рейтинг , который низкий в реальной жизни (Ложно положительный)\n",
    "## Необходимо замеить accuracy на precision macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "665133eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_macro = make_scorer(precision_score, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07fd601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: best_params={'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'linear', 'probability': True, 'random_state': 21}, precision_score=0.3867\n",
      "Stacking Classifier: best_params={'final_estimator': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression', LogisticRegression(max_iter=1000))]), 'passthrough': True}, precision_score=0.4315\n",
      "Bagging Classifier: best_params={'bootstrap': True, 'bootstrap_features': False, 'estimator': DecisionTreeClassifier(max_depth=3), 'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 10}, precision_score=0.4988\n",
      "Logistic Regression: best_params={'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}, precision_score=0.4714\n",
      "VotingClassifier: best_params={'voting': 'hard', 'weights': [1, 1, 1]}, precision_score=0.5003\n"
     ]
    }
   ],
   "source": [
    "classificator_result_labels_precision = compare_classificators(classificators_and_params,X_train.iloc[:5000],y_train_labeled.iloc[:5000],X_test,y_test_labeled,cv=3,scoring=precision_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db3422b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best classificator class VotingClassifier, hyperparametrs: {'voting': 'hard', 'weights': [1, 1, 1]}, precision_macro = 0.5003095766875294\n"
     ]
    }
   ],
   "source": [
    "classificator_result_labels_precision.sort(key=lambda x:-x[2])\n",
    "print(f'Best classificator class {classificator_result_labels_precision[0][0]}, hyperparametrs: {classificator_result_labels_precision[0][1]}, precision_macro = {classificator_result_labels_precision[0][2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2128edca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Naive model = 0.2647117494514263\n"
     ]
    }
   ],
   "source": [
    "naive_precision_labels = precision_score(y_test_labeled,most_common_label,average='macro')\n",
    "print(f'Precision of Naive model = {naive_precision_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde17c53",
   "metadata": {},
   "source": [
    "## Decision: что лучше использовать — регрессию или классификацию?\n",
    "### Сравнение результатов\n",
    "#### Регрессия:\n",
    "\n",
    "Лучшая модель (Gradient Boosting): RMSE ≈ 1.27\n",
    "\n",
    "Наивная регрессия (среднее): RMSE ≈ 1.33\n",
    "\n",
    "Выигрыш по сравнению с наивной: ≈5%\n",
    "\n",
    "Ошибка (1.27 балла) — большая относительно шкалы рейтинга (от 0 до 5).\n",
    "\n",
    "#### Классификация (3 класса: “bad”, “so-so”, “great”):\n",
    "\n",
    "Лучшая accuracy моделей: 0.80\n",
    "\n",
    "Accuracy наивной модели: 0.73\n",
    "\n",
    "Лучшая macro-precision: 0.50\n",
    "\n",
    "Macro-precision наивной модели: 0.24\n",
    "\n",
    "Модели выигрывают у наивного по macro-precision примерно на 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e9671",
   "metadata": {},
   "source": [
    "### Аргументы в пользу классификации\n",
    "Accuracy и macro-precision у моделей классификации выше, чем у наивной, и прирост значимее, чем у регрессии.\n",
    "\n",
    "Регрессия в этой задаче не даёт точного результата (ошибка 1.27 — это очень много по 5-балльной шкале), практической ценности мало.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86eb97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_precision_params = classificator_result_labels_precision[0][1]\n",
    "precision_model = make_pipeline(StandardScaler(),VotingClassifier(base_learners_VC,**best_precision_params))\n",
    "precision_model.fit(X_train,y_train_labeled)\n",
    "precision_y_pred = precision_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49344adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.66      0.09      0.15       487\n",
      "       great       0.80      1.00      0.89      3981\n",
      "       so-so       1.00      0.00      0.00       545\n",
      "\n",
      "    accuracy                           0.80      5013\n",
      "   macro avg       0.82      0.36      0.35      5013\n",
      "weighted avg       0.81      0.80      0.72      5013\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  42  445    0]\n",
      " [  18 3963    0]\n",
      " [   4  541    0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labeled, precision_y_pred, zero_division=1))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_labeled, precision_y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "90c7d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy_params = classificator_result_labels[0][1]\n",
    "accuracy_model = make_pipeline(StandardScaler(),VotingClassifier(base_learners_VC, **best_accuracy_params))\n",
    "accuracy_model.fit(X_train,y_train_labeled)\n",
    "accuracy_y_pred = accuracy_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53788a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.64      0.10      0.17       487\n",
      "       great       0.80      0.99      0.89      3981\n",
      "       so-so       1.00      0.00      0.00       545\n",
      "\n",
      "    accuracy                           0.80      5013\n",
      "   macro avg       0.82      0.36      0.35      5013\n",
      "weighted avg       0.81      0.80      0.72      5013\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  47  440    0]\n",
      " [  22 3959    0]\n",
      " [   4  540    1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labeled, accuracy_y_pred, zero_division=1))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_labeled, accuracy_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27182a8",
   "metadata": {},
   "source": [
    "Результаты обеих моделей (максимальная accuracy и максимальная macro-precision) практически совпадают. Обе модели хорошо предсказывают основной класс (`great`), плохо — редкие (`so-so`, `bad`). Различия в метриках минимальны.\n",
    "\n",
    "**Вывод:**  \n",
    "Выбираем модель с максимальной accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edb891d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/VotingClassifier_0.79932.sav']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model_accuracy = accuracy_score(y_test_labeled, accuracy_y_pred)\n",
    "model_filename = f\"data/VotingClassifier_{round(accuracy_model_accuracy,5)}.sav\"\n",
    "joblib.dump(accuracy_model,model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93138c0a4a845e9",
   "metadata": {},
   "source": [
    "Nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd28b3ea2f1daf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T13:20:24.690448Z",
     "start_time": "2025-06-10T13:20:24.337124Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f77c56e8d42480db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T13:20:37.574896Z",
     "start_time": "2025-06-10T13:20:37.566377Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients = list(x.columns)\n",
    "daily_values = {\n",
    "    \"Vitamin A, RAE\": 900 , \"Vitamin E (alpha-tocopherol)\": 15 * 1000, 'Manganese, Mn': 2.3 * 1000, 'Folate, total': 400 * 1000,\n",
    "    \"Total lipid (fat)\": 78 * 1000000, \"Fatty acids, total saturated\": 20 * 1000000, \"Cholesterol\": 300 * 1000, \n",
    "    \"Vitamin D (D2 + D3)\": 20 , \"Vitamin K (phylloquinone)\": 120 , \"Calcium, Ca\": 1300 * 1000, \n",
    "    \"Iron, Fe\": 18 * 1000, \"Thiamin\": 1.2 * 1000, \"Riboflavin\": 1.3 * 1000, \"Niacin\": 16 * 1000, \"Vitamin B-6\": 1.7 * 1000, \n",
    "    \"Folate, DFE\": 400 , \"Sodium, Na\": 2300 * 1000, \"Phosphorus, P\": 1250 * 1000, \"Magnesium, Mg\": 420 * 1000, \n",
    "    \"Zinc, Zn\": 11 * 1000, \"Copper, Cu\": 0.9 * 1000, \"Selenium, Se\": 55 * 1000, \n",
    "    \"Carbohydrate, by difference\": 275 * 1000000, \"Fiber, total dietary\": 28 * 1000000, \"Choline, total\": 2300 * 1000, \n",
    "    \"Potassium, K\": 4700 * 1000, \"Protein\": 50 * 1000000, \"Vitamin B-12, added\": 2.4 , \"Total Sugars\": 50 * 10000000\n",
    "}\n",
    "\n",
    "def data_make(ingredients, daily_values):\n",
    "    api_key = \"tbVKCwicj5dE4uZ2L8QAORdd5AmPXTZwcEyvYqVn\"\n",
    "    nutrients_list_result = []\n",
    "    for item in ingredients:\n",
    "        search_response = requests.get('https://api.nal.usda.gov/fdc/v1/foods/search?api_key={}&query={}'.format(api_key, item)).json()\n",
    "        \n",
    "        if not search_response.get(\"foods\"):\n",
    "            continue\n",
    "        \n",
    "        fdc_id = search_response[\"foods\"][0][\"fdcId\"]\n",
    "\n",
    "        food_url = f\"https://api.nal.usda.gov/fdc/v1/food/{fdc_id}?api_key={api_key}\"\n",
    "        food_data = requests.get(food_url).json()\n",
    "\n",
    "        nutrients_list = []\n",
    "        for nutrient_data in food_data.get(\"foodNutrients\", []):\n",
    "            try:\n",
    "                name = nutrient_data[\"nutrient\"][\"name\"]\n",
    "                amount = nutrient_data[\"amount\"]\n",
    "                unit = nutrient_data[\"nutrient\"][\"unitName\"] \n",
    "                if ( unit == 'mg'):\n",
    "                    amount = amount * 1000\n",
    "                if ( unit == 'g'):\n",
    "                    amount = amount * 1000000\n",
    "                if (name in daily_values.keys()):\n",
    "                    nutrients_list.append({\n",
    "                        \"name\": name,\n",
    "                        \"amount\": (amount/daily_values[name]),\n",
    "                        \"unit\": unit\n",
    "                    })\n",
    "            \n",
    "            except KeyError as e:\n",
    "                continue \n",
    "            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        nutrients_list_result.append({item: nutrients_list})\n",
    "\n",
    "    return  nutrients_list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "567713c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data_make(ingredients, daily_values)\n",
    "df2 = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abbbd4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein</th>\n",
       "      <th>Total lipid (fat)</th>\n",
       "      <th>Carbohydrate, by difference</th>\n",
       "      <th>Total Sugars</th>\n",
       "      <th>Fiber, total dietary</th>\n",
       "      <th>Calcium, Ca</th>\n",
       "      <th>Iron, Fe</th>\n",
       "      <th>Magnesium, Mg</th>\n",
       "      <th>Phosphorus, P</th>\n",
       "      <th>Potassium, K</th>\n",
       "      <th>...</th>\n",
       "      <th>Niacin</th>\n",
       "      <th>Vitamin B-6</th>\n",
       "      <th>Folate, total</th>\n",
       "      <th>Choline, total</th>\n",
       "      <th>Vitamin K (phylloquinone)</th>\n",
       "      <th>Folate, DFE</th>\n",
       "      <th>Vitamin B-12, added</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Fatty acids, total saturated</th>\n",
       "      <th>Manganese, Mn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>almond</th>\n",
       "      <td>0.4140</td>\n",
       "      <td>0.675641</td>\n",
       "      <td>0.076727</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.202308</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.157660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243125</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amaretto</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.06666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anchovy</th>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.124487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178462</td>\n",
       "      <td>0.257222</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.115745</td>\n",
       "      <td>...</td>\n",
       "      <td>1.243750</td>\n",
       "      <td>0.119412</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.036957</td>\n",
       "      <td>0.100833</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anise</th>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.203846</td>\n",
       "      <td>0.181891</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.496923</td>\n",
       "      <td>2.053333</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.306596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.051964</td>\n",
       "      <td>0.02078</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow squash</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yogurt</th>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>0.00616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.032766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuca</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106945</td>\n",
       "      <td>0.00236</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.009231</td>\n",
       "      <td>0.070556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.075106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zucchini</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.047234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turkey</th>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.016282</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.00338</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Protein  Total lipid (fat)  Carbohydrate, by difference  \\\n",
       "almond          0.4140           0.675641                     0.076727   \n",
       "amaretto        0.0000           0.128205                     0.121200   \n",
       "anchovy         0.5780           0.124487                     0.000000   \n",
       "anise           0.3520           0.203846                     0.181891   \n",
       "apple           0.0000           0.008333                     0.051964   \n",
       "...                ...                ...                          ...   \n",
       "yellow squash   0.0200           0.000000                     0.010909   \n",
       "yogurt          0.0704           0.045128                     0.016036   \n",
       "yuca            0.0236           0.000000                     0.106945   \n",
       "zucchini        0.0210           0.000000                     0.015309   \n",
       "turkey          0.1950           0.016282                     0.024655   \n",
       "\n",
       "               Total Sugars  Fiber, total dietary  Calcium, Ca  Iron, Fe  \\\n",
       "almond              0.00880              0.342857     0.202308  0.226667   \n",
       "amaretto            0.06666              0.000000     0.000000  0.000000   \n",
       "anchovy             0.00000              0.000000     0.178462  0.257222   \n",
       "anise               0.00000              0.521429     0.496923  2.053333   \n",
       "apple               0.02078              0.114286     0.000000  0.012778   \n",
       "...                     ...                   ...          ...       ...   \n",
       "yellow squash       0.00400              0.035714     0.007692  0.020000   \n",
       "yogurt              0.00616              0.000000     0.101538  0.000000   \n",
       "yuca                0.00236              0.125000     0.009231  0.070556   \n",
       "zucchini            0.00632              0.039286     0.016154  0.024444   \n",
       "turkey              0.00338              0.046429     0.032308  0.063333   \n",
       "\n",
       "               Magnesium, Mg  Phosphorus, P  Potassium, K  ...    Niacin  \\\n",
       "almond              0.633333         0.4032      0.157660  ...  0.243125   \n",
       "amaretto            0.000000         0.0000      0.000000  ...  0.000000   \n",
       "anchovy             0.164286         0.2016      0.115745  ...  1.243750   \n",
       "anise               0.404762         0.3520      0.306596  ...  0.191250   \n",
       "apple               0.000000         0.0000      0.023404  ...  0.000000   \n",
       "...                      ...            ...           ...  ...       ...   \n",
       "yellow squash       0.000000         0.0000      0.000000  ...  0.000000   \n",
       "yogurt              0.030952         0.0000      0.032766  ...  0.000000   \n",
       "yuca                0.000000         0.0000      0.075106  ...  0.000000   \n",
       "zucchini            0.000000         0.0000      0.047234  ...  0.000000   \n",
       "turkey              0.000000         0.0000      0.000000  ...  0.000000   \n",
       "\n",
       "               Vitamin B-6  Folate, total  Choline, total  \\\n",
       "almond            0.048824       0.000105        0.022522   \n",
       "amaretto          0.000000       0.000000        0.000000   \n",
       "anchovy           0.119412       0.000032        0.036957   \n",
       "anise             0.382353       0.000025        0.000000   \n",
       "apple             0.000000       0.000000        0.000000   \n",
       "...                    ...            ...             ...   \n",
       "yellow squash     0.000000       0.000000        0.000000   \n",
       "yogurt            0.000000       0.000000        0.000000   \n",
       "yuca              0.000000       0.000000        0.000000   \n",
       "zucchini          0.000000       0.000000        0.000000   \n",
       "turkey            0.000000       0.000000        0.000000   \n",
       "\n",
       "               Vitamin K (phylloquinone)  Folate, DFE  Vitamin B-12, added  \\\n",
       "almond                          0.000000       0.1050                  0.0   \n",
       "amaretto                        0.000000       0.0000                  0.0   \n",
       "anchovy                         0.100833       0.0325                  0.0   \n",
       "anise                           0.000000       0.0250                  0.0   \n",
       "apple                           0.000000       0.0000                  0.0   \n",
       "...                                  ...          ...                  ...   \n",
       "yellow squash                   0.000000       0.0000                  0.0   \n",
       "yogurt                          0.000000       0.0000                  0.0   \n",
       "yuca                            0.000000       0.0000                  0.0   \n",
       "zucchini                        0.000000       0.0000                  0.0   \n",
       "turkey                          0.000000       0.0000                  0.0   \n",
       "\n",
       "               Cholesterol  Fatty acids, total saturated  Manganese, Mn  \n",
       "almond            0.000000                        0.2110            0.0  \n",
       "amaretto          0.000000                        0.1665            0.0  \n",
       "anchovy           0.283333                        0.1100            0.0  \n",
       "anise             0.000000                        0.0293            1.0  \n",
       "apple             0.000000                        0.0000            0.0  \n",
       "...                    ...                           ...            ...  \n",
       "yellow squash     0.000000                        0.0000            0.0  \n",
       "yogurt            0.050000                        0.1100            0.0  \n",
       "yuca              0.000000                        0.0000            0.0  \n",
       "zucchini          0.000000                        0.0000            0.0  \n",
       "turkey            0.113333                        0.0210            0.0  \n",
       "\n",
       "[343 rows x 29 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for product_dict in df1:\n",
    "    product_name = list(product_dict.keys())[0]\n",
    "    nutrients = product_dict[product_name]\n",
    "    \n",
    "    for nutrient in nutrients:\n",
    "        col_name = f\"{nutrient['name']}\"\n",
    "        df2.loc[product_name, col_name] = nutrient['amount']\n",
    "\n",
    "df2 = df2.fillna(0)\n",
    "df2.to_csv('data/nutritions_facts.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0f62f",
   "metadata": {},
   "source": [
    "Similar Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ee334d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pd.notna(row[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m      4\u001b[39m         recipe_urls.append({\n\u001b[32m      5\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://www.epicurious.com/recipes/food/views/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m).lower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m         })\n",
      "\u001b[31mAttributeError\u001b[39m: 'int' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "recipe_urls = []\n",
    "for _, row in df.iterrows():\n",
    "    if pd.notna(row['title']):\n",
    "        recipe_urls.append({\n",
    "            \"title\": row[\"title\"],\n",
    "            \"rating\": row[\"rating\"],\n",
    "            \"url\": f\"https://www.epicurious.com/recipes/food/views/{row['title'].replace(' ', '-').lower()}\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_urls_df = pd.DataFrame(recipe_urls)\n",
    "recipe_urls_df.to_csv(\"data/similar_recipes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
